{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install exetera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 KCL-BMEIS - King's College London\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "import h5py\n",
    "\n",
    "from exetera.processing.age_from_year_of_birth import calculate_age_from_year_of_birth_fast\n",
    "from exetera.processing.weight_height_bmi import weight_height_bmi_fast_1\n",
    "from exetera.processing.inconsistent_symptoms import check_inconsistent_symptoms_1\n",
    "from exetera.processing.temperature import validate_temperature_1\n",
    "from exetera.processing.combined_healthcare_worker import combined_hcw_with_contact\n",
    "from exetera.core import persistence\n",
    "from exetera.core.persistence import DataStore\n",
    "from exetera.core.session import Session\n",
    "from exetera.core import readerwriter as rw\n",
    "from exetera.core import utils\n",
    "\n",
    "def log(*a, **kwa):\n",
    "    print(*a, **kwa)\n",
    "\n",
    "\n",
    "def postprocess(dataset, destination, timestamp=None, flags=None):\n",
    "\n",
    "    if flags is None:\n",
    "        flags = set()\n",
    "\n",
    "    do_daily_asmts = 'daily' in flags\n",
    "    has_patients = 'patients' in dataset.keys()\n",
    "    has_assessments = 'assessments' in dataset.keys()\n",
    "    has_tests = 'tests' in dataset.keys()\n",
    "    has_diet = 'diet' in dataset.keys()\n",
    "\n",
    "    sort_enabled = lambda x: True\n",
    "    process_enabled = lambda x: True\n",
    "\n",
    "    sort_patients = sort_enabled(flags) and True\n",
    "    sort_assessments = sort_enabled(flags) and True\n",
    "    sort_tests = sort_enabled(flags) and True\n",
    "    sort_diet = sort_enabled(flags) and True\n",
    "\n",
    "    make_assessment_patient_id_fkey = process_enabled(flags) and True\n",
    "    year_from_age = process_enabled(flags) and True\n",
    "    clean_weight_height_bmi = process_enabled(flags) and True\n",
    "    health_worker_with_contact = process_enabled(flags) and True\n",
    "    clean_temperatures = process_enabled(flags) and True\n",
    "    check_symptoms = process_enabled(flags) and True\n",
    "    create_daily = process_enabled(flags) and do_daily_asmts\n",
    "    make_patient_level_assessment_metrics = process_enabled(flags) and True\n",
    "    make_patient_level_daily_assessment_metrics = process_enabled(flags) and do_daily_asmts\n",
    "    make_new_test_level_metrics = process_enabled(flags) and True\n",
    "    make_diet_level_metrics = True\n",
    "    make_healthy_diet_index = True\n",
    "\n",
    "    ds = DataStore(timestamp=timestamp)\n",
    "    s = Session()\n",
    "\n",
    "    # patients ================================================================\n",
    "\n",
    "    sorted_patients_src = None\n",
    "\n",
    "    if has_patients:\n",
    "        patients_src = dataset['patients']\n",
    "\n",
    "        write_mode = 'write'\n",
    "\n",
    "        if 'patients' not in destination.keys():\n",
    "            patients_dest = ds.get_or_create_group(destination, 'patients')\n",
    "            sorted_patients_src = patients_dest\n",
    "\n",
    "            # Patient sort\n",
    "            # ============\n",
    "            if sort_patients:\n",
    "                duplicate_filter = \\\n",
    "                    persistence.filter_duplicate_fields(ds.get_reader(patients_src['id'])[:])\n",
    "\n",
    "                for k in patients_src.keys():\n",
    "                    t0 = time.time()\n",
    "                    r = ds.get_reader(patients_src[k])\n",
    "                    w = r.get_writer(patients_dest, k)\n",
    "                    ds.apply_filter(duplicate_filter, r, w)\n",
    "                    print(f\"'{k}' filtered in {time.time() - t0}s\")\n",
    "\n",
    "                print(np.count_nonzero(duplicate_filter == True),\n",
    "                      np.count_nonzero(duplicate_filter == False))\n",
    "                sort_keys = ('id',)\n",
    "                ds.sort_on(\n",
    "                    patients_dest, patients_dest, sort_keys, write_mode='overwrite')\n",
    "\n",
    "            # Patient processing\n",
    "            # ==================\n",
    "            if year_from_age:\n",
    "                log(\"year of birth -> age; 18 to 90 filter\")\n",
    "                t0 = time.time()\n",
    "                age = ds.get_numeric_writer(patients_dest, 'age', 'uint32',\n",
    "                                            write_mode)\n",
    "                age_filter = ds.get_numeric_writer(patients_dest, 'age_filter',\n",
    "                                                   'bool', write_mode)\n",
    "                age_16_to_90 = ds.get_numeric_writer(patients_dest, '16_to_90_years',\n",
    "                                                     'bool', write_mode)\n",
    "                print('year_of_birth:', patients_dest['year_of_birth'])\n",
    "                for k in patients_dest['year_of_birth'].attrs.keys():\n",
    "                    print(k, patients_dest['year_of_birth'].attrs[k])\n",
    "                calculate_age_from_year_of_birth_fast(\n",
    "                    ds, 16, 90,\n",
    "                    patients_dest['year_of_birth'], patients_dest['year_of_birth_valid'],\n",
    "                    age, age_filter, age_16_to_90,\n",
    "                    2020)\n",
    "                log(f\"completed in {time.time() - t0}\")\n",
    "\n",
    "                print('age_filter count:', np.sum(patients_dest['age_filter']['values'][:]))\n",
    "                print('16_to_90_years count:', np.sum(patients_dest['16_to_90_years']['values'][:]))\n",
    "\n",
    "            if clean_weight_height_bmi:\n",
    "                log(\"height / weight / bmi; standard range filters\")\n",
    "                t0 = time.time()\n",
    "\n",
    "                weights_clean = ds.get_numeric_writer(patients_dest, 'weight_kg_clean',\n",
    "                                                      'float32', write_mode)\n",
    "                weights_filter = ds.get_numeric_writer(patients_dest, '40_to_200_kg',\n",
    "                                                       'bool', write_mode)\n",
    "                heights_clean = ds.get_numeric_writer(patients_dest, 'height_cm_clean',\n",
    "                                                      'float32', write_mode)\n",
    "                heights_filter = ds.get_numeric_writer(patients_dest, '110_to_220_cm',\n",
    "                                                       'bool', write_mode)\n",
    "                bmis_clean = ds.get_numeric_writer(patients_dest, 'bmi_clean',\n",
    "                                                   'float32', write_mode)\n",
    "                bmis_filter = ds.get_numeric_writer(patients_dest, '15_to_55_bmi',\n",
    "                                                    'bool', write_mode)\n",
    "\n",
    "                weight_height_bmi_fast_1(ds, 40, 200, 110, 220, 15, 55,\n",
    "                                         None, None, None, None,\n",
    "                                         patients_dest['weight_kg'], patients_dest['weight_kg_valid'],\n",
    "                                         patients_dest['height_cm'], patients_dest['height_cm_valid'],\n",
    "                                         patients_dest['bmi'], patients_dest['bmi_valid'],\n",
    "                                         weights_clean, weights_filter, None,\n",
    "                                         heights_clean, heights_filter, None,\n",
    "                                         bmis_clean, bmis_filter, None)\n",
    "                log(f\"completed in {time.time() - t0}\")\n",
    "\n",
    "            if health_worker_with_contact:\n",
    "                with utils.Timer(\"health_worker_with_contact field\"):\n",
    "                    #writer = ds.get_categorical_writer(patients_dest, 'health_worker_with_contact', 'int8')\n",
    "                    combined_hcw_with_contact(ds,\n",
    "                                              ds.get_reader(patients_dest['healthcare_professional']),\n",
    "                                              ds.get_reader(patients_dest['contact_health_worker']),\n",
    "                                              ds.get_reader(patients_dest['is_carer_for_community']),\n",
    "                                              patients_dest, 'health_worker_with_contact')\n",
    "\n",
    "    # assessments =============================================================\n",
    "\n",
    "    sorted_assessments_src = None\n",
    "    if has_assessments:\n",
    "        assessments_src = dataset['assessments']\n",
    "        if 'assessments' not in destination.keys():\n",
    "            assessments_dest = ds.get_or_create_group(destination, 'assessments')\n",
    "            sorted_assessments_src = assessments_dest\n",
    "\n",
    "            if sort_assessments:\n",
    "                sort_keys = ('patient_id', 'created_at')\n",
    "                with utils.Timer(\"sorting assessments\"):\n",
    "                    ds.sort_on(\n",
    "                        assessments_src, assessments_dest, sort_keys)\n",
    "\n",
    "            if has_patients:\n",
    "                if make_assessment_patient_id_fkey:\n",
    "                    print(\"creating 'assessment_patient_id_fkey' foreign key index for 'patient_id'\")\n",
    "                    t0 = time.time()\n",
    "                    patient_ids = ds.get_reader(sorted_patients_src['id'])\n",
    "                    assessment_patient_ids =\\\n",
    "                        ds.get_reader(sorted_assessments_src['patient_id'])\n",
    "                    assessment_patient_id_fkey =\\\n",
    "                        ds.get_numeric_writer(assessments_dest, 'assessment_patient_id_fkey', 'int64')\n",
    "                    ds.get_index(patient_ids, assessment_patient_ids, assessment_patient_id_fkey)\n",
    "                    print(f\"completed in {time.time() - t0}s\")\n",
    "\n",
    "            if clean_temperatures:\n",
    "                print(\"clean temperatures\")\n",
    "                t0 = time.time()\n",
    "                temps = ds.get_reader(sorted_assessments_src['temperature'])\n",
    "                temp_units = ds.get_reader(sorted_assessments_src['temperature_unit'])\n",
    "                temps_valid = ds.get_reader(sorted_assessments_src['temperature_valid'])\n",
    "                dest_temps = temps.get_writer(assessments_dest, 'temperature_c_clean', write_mode)\n",
    "                dest_temps_valid =\\\n",
    "                    temps_valid.get_writer(assessments_dest, 'temperature_35_to_42_inclusive', write_mode)\n",
    "                dest_temps_modified =\\\n",
    "                    temps_valid.get_writer(assessments_dest, 'temperature_modified', write_mode)\n",
    "                validate_temperature_1(35.0, 42.0,\n",
    "                                       temps, temp_units, temps_valid,\n",
    "                                       dest_temps, dest_temps_valid, dest_temps_modified)\n",
    "                print(f\"temperature cleaning done in {time.time() - t0}\")\n",
    "\n",
    "            if check_symptoms:\n",
    "                print('check inconsistent health_status')\n",
    "                t0 = time.time()\n",
    "                check_inconsistent_symptoms_1(ds, sorted_assessments_src, assessments_dest)\n",
    "                print(time.time() - t0)\n",
    "\n",
    "    # tests ===================================================================\n",
    "\n",
    "    if has_tests:\n",
    "        if sort_tests:\n",
    "            tests_src = dataset['tests']\n",
    "            tests_dest = ds.get_or_create_group(destination, 'tests')\n",
    "            sort_keys = ('patient_id', 'created_at')\n",
    "            ds.sort_on(tests_src, tests_dest, sort_keys)\n",
    "\n",
    "    # diet ====================================================================\n",
    "\n",
    "    if has_diet:\n",
    "        diet_src = dataset['diet']\n",
    "        if 'diet' not in destination.keys():\n",
    "            diet_dest = ds.get_or_create_group(destination, 'diet')\n",
    "            sorted_diet_src = diet_dest\n",
    "            if sort_diet:\n",
    "                sort_keys = ('patient_id', 'display_name', 'id')\n",
    "                ds.sort_on(diet_src, diet_dest, sort_keys)\n",
    "\n",
    "\n",
    "    if has_assessments:\n",
    "        if do_daily_asmts:\n",
    "            daily_assessments_dest = ds.get_or_create_group(destination, 'daily_assessments')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # post process patients\n",
    "    # TODO: need an transaction table\n",
    "\n",
    "    print(patients_src.keys())\n",
    "    print(dataset['assessments'].keys())\n",
    "    print(dataset['tests'].keys())\n",
    "\n",
    "    # write_mode = 'overwrite'\n",
    "    write_mode = 'write'\n",
    "\n",
    "\n",
    "    # Daily assessments\n",
    "    # =================\n",
    "\n",
    "    if has_assessments:\n",
    "        if create_daily:\n",
    "            print(\"generate daily assessments\")\n",
    "            patient_ids = ds.get_reader(sorted_assessments_src['patient_id'])\n",
    "            created_at_days = ds.get_reader(sorted_assessments_src['created_at_day'])\n",
    "            raw_created_at_days = created_at_days[:]\n",
    "\n",
    "            if 'assessment_patient_id_fkey' in assessments_src.keys():\n",
    "                patient_id_index = assessments_src['assessment_patient_id_fkey']\n",
    "            else:\n",
    "                patient_id_index = assessments_dest['assessment_patient_id_fkey']\n",
    "            patient_id_indices = ds.get_reader(patient_id_index)\n",
    "            raw_patient_id_indices = patient_id_indices[:]\n",
    "\n",
    "\n",
    "            print(\"Calculating patient id index spans\")\n",
    "            t0 = time.time()\n",
    "            patient_id_index_spans = ds.get_spans(fields=(raw_patient_id_indices,\n",
    "                                                         raw_created_at_days))\n",
    "            print(f\"Calculated {len(patient_id_index_spans)-1} spans in {time.time() - t0}s\")\n",
    "\n",
    "\n",
    "            print(\"Applying spans to 'health_status'\")\n",
    "            t0 = time.time()\n",
    "            default_behavour_overrides = {\n",
    "                'id': ds.apply_spans_last,\n",
    "                'patient_id': ds.apply_spans_last,\n",
    "                'patient_index': ds.apply_spans_last,\n",
    "                'created_at': ds.apply_spans_last,\n",
    "                'created_at_day': ds.apply_spans_last,\n",
    "                'updated_at': ds.apply_spans_last,\n",
    "                'updated_at_day': ds.apply_spans_last,\n",
    "                'version': ds.apply_spans_max,\n",
    "                'country_code': ds.apply_spans_first,\n",
    "                'date_test_occurred': None,\n",
    "                'date_test_occurred_guess': None,\n",
    "                'date_test_occurred_day': None,\n",
    "                'date_test_occurred_set': None,\n",
    "            }\n",
    "            for k in sorted_assessments_src.keys():\n",
    "                t1 = time.time()\n",
    "                reader = ds.get_reader(sorted_assessments_src[k])\n",
    "                if k in default_behavour_overrides:\n",
    "                    apply_span_fn = default_behavour_overrides[k]\n",
    "                    if apply_span_fn is not None:\n",
    "                        apply_span_fn(patient_id_index_spans, reader,\n",
    "                                      reader.get_writer(daily_assessments_dest, k))\n",
    "                        print(f\"  Field {k} aggregated in {time.time() - t1}s\")\n",
    "                    else:\n",
    "                        print(f\"  Skipping field {k}\")\n",
    "                else:\n",
    "                    if isinstance(reader, rw.CategoricalReader):\n",
    "                        ds.apply_spans_max(\n",
    "                            patient_id_index_spans, reader,\n",
    "                            reader.get_writer(daily_assessments_dest, k))\n",
    "                        print(f\"  Field {k} aggregated in {time.time() - t1}s\")\n",
    "                    elif isinstance(reader, rw.IndexedStringReader):\n",
    "                        ds.apply_spans_concat(\n",
    "                            patient_id_index_spans, reader,\n",
    "                            reader.get_writer(daily_assessments_dest, k))\n",
    "                        print(f\"  Field {k} aggregated in {time.time() - t1}s\")\n",
    "                    elif isinstance(reader, rw.NumericReader):\n",
    "                        ds.apply_spans_max(\n",
    "                            patient_id_index_spans, reader,\n",
    "                            reader.get_writer(daily_assessments_dest, k))\n",
    "                        print(f\"  Field {k} aggregated in {time.time() - t1}s\")\n",
    "                    else:\n",
    "                        print(f\"  No function for {k}\")\n",
    "\n",
    "            print(f\"apply_spans completed in {time.time() - t0}s\")\n",
    "\n",
    "    if has_patients and has_assessments:\n",
    "            if make_patient_level_assessment_metrics:\n",
    "                if 'assessment_patient_id_fkey' in assessments_dest:\n",
    "                    src = assessments_dest['assessment_patient_id_fkey']\n",
    "                else:\n",
    "                    src = assessments_src['assessment_patient_id_fkey']\n",
    "                assessment_patient_id_fkey = ds.get_reader(src)\n",
    "                # generate spans from the assessment-space patient_id foreign key\n",
    "                spans = ds.get_spans(field=assessment_patient_id_fkey)\n",
    "\n",
    "                ids = ds.get_reader(patients_dest['id'])\n",
    "\n",
    "                print('calculate assessment counts per patient')\n",
    "                t0 = time.time()\n",
    "                writer = ds.get_numeric_writer(patients_dest, 'assessment_count', 'uint32')\n",
    "                aggregated_counts = ds.aggregate_count(fkey_index_spans=spans)\n",
    "                ds.join(ids, assessment_patient_id_fkey, aggregated_counts, writer, spans)\n",
    "                print(f\"calculated assessment counts per patient in {time.time() - t0}\")\n",
    "\n",
    "                print('calculate first assessment days per patient')\n",
    "                t0 = time.time()\n",
    "                reader = ds.get_reader(sorted_assessments_src['created_at_day'])\n",
    "                writer = ds.get_fixed_string_writer(patients_dest, 'first_assessment_day', 10)\n",
    "                aggregated_counts = ds.aggregate_first(fkey_index_spans=spans, reader=reader)\n",
    "                ds.join(ids, assessment_patient_id_fkey, aggregated_counts, writer, spans)\n",
    "                print(f\"calculated first assessment days per patient in {time.time() - t0}\")\n",
    "\n",
    "                print('calculate last assessment days per patient')\n",
    "                t0 = time.time()\n",
    "                reader = ds.get_reader(sorted_assessments_src['created_at_day'])\n",
    "                writer = ds.get_fixed_string_writer(patients_dest, 'last_assessment_day', 10)\n",
    "                aggregated_counts = ds.aggregate_last(fkey_index_spans=spans, reader=reader)\n",
    "                ds.join(ids, assessment_patient_id_fkey, aggregated_counts, writer, spans)\n",
    "                print(f\"calculated last assessment days per patient in {time.time() - t0}\")\n",
    "\n",
    "                print('calculate maximum assessment test result per patient')\n",
    "                t0 = time.time()\n",
    "                reader = ds.get_reader(sorted_assessments_src['tested_covid_positive'])\n",
    "                writer = reader.get_writer(patients_dest, 'max_assessment_test_result')\n",
    "                max_result_value = ds.aggregate_max(fkey_index_spans=spans, reader=reader)\n",
    "                ds.join(ids, assessment_patient_id_fkey, max_result_value, writer, spans)\n",
    "                print(f\"calculated maximum assessment test result in {time.time() - t0}\")\n",
    "\n",
    "\n",
    "    if has_assessments and do_daily_asmts and make_patient_level_daily_assessment_metrics:\n",
    "        print(\"creating 'daily_assessment_patient_id_fkey' foreign key index for 'patient_id'\")\n",
    "        t0 = time.time()\n",
    "        patient_ids = ds.get_reader(sorted_patients_src['id'])\n",
    "        daily_assessment_patient_ids =\\\n",
    "            ds.get_reader(daily_assessments_dest['patient_id'])\n",
    "        daily_assessment_patient_id_fkey =\\\n",
    "            ds.get_numeric_writer(daily_assessments_dest, 'daily_assessment_patient_id_fkey',\n",
    "                                  'int64')\n",
    "        ds.get_index(patient_ids, daily_assessment_patient_ids,\n",
    "                     daily_assessment_patient_id_fkey)\n",
    "        print(f\"completed in {time.time() - t0}s\")\n",
    "\n",
    "        spans = ds.get_spans(\n",
    "            field=ds.get_reader(daily_assessments_dest['daily_assessment_patient_id_fkey']))\n",
    "\n",
    "        print('calculate daily assessment counts per patient')\n",
    "        t0 = time.time()\n",
    "        writer = ds.get_numeric_writer(patients_dest, 'daily_assessment_count', 'uint32')\n",
    "        aggregated_counts = ds.aggregate_count(fkey_index_spans=spans)\n",
    "        daily_assessment_patient_id_fkey =\\\n",
    "            ds.get_reader(daily_assessments_dest['daily_assessment_patient_id_fkey'])\n",
    "        ds.join(ids, daily_assessment_patient_id_fkey, aggregated_counts, writer, spans)\n",
    "        print(f\"calculated daily assessment counts per patient in {time.time() - t0}\")\n",
    "\n",
    "\n",
    "    # TODO - new test count per patient:\n",
    "    if has_tests and make_new_test_level_metrics:\n",
    "        print(\"creating 'test_patient_id_fkey' foreign key index for 'patient_id'\")\n",
    "        t0 = time.time()\n",
    "        patient_ids = ds.get_reader(sorted_patients_src['id'])\n",
    "        test_patient_ids = ds.get_reader(tests_dest['patient_id'])\n",
    "        test_patient_id_fkey = ds.get_numeric_writer(tests_dest, 'test_patient_id_fkey',\n",
    "                                                     'int64')\n",
    "        ds.get_index(patient_ids, test_patient_ids, test_patient_id_fkey)\n",
    "        test_patient_id_fkey = ds.get_reader(tests_dest['test_patient_id_fkey'])\n",
    "        spans = ds.get_spans(field=test_patient_id_fkey)\n",
    "        print(f\"completed in {time.time() - t0}s\")\n",
    "\n",
    "        print('calculate test_counts per patient')\n",
    "        t0 = time.time()\n",
    "        writer = ds.get_numeric_writer(patients_dest, 'test_count', 'uint32')\n",
    "        aggregated_counts = ds.aggregate_count(fkey_index_spans=spans)\n",
    "        ds.join(ids, test_patient_id_fkey, aggregated_counts, writer, spans)\n",
    "        print(f\"calculated test counts per patient in {time.time() - t0}\")\n",
    "\n",
    "        print('calculate test_result per patient')\n",
    "        t0 = time.time()\n",
    "        test_results = ds.get_reader(tests_dest['result'])\n",
    "        writer = test_results.get_writer(patients_dest, 'max_test_result')\n",
    "        aggregated_results = ds.aggregate_max(fkey_index_spans=spans, reader=test_results)\n",
    "        ds.join(ids, test_patient_id_fkey, aggregated_results, writer, spans)\n",
    "        print(f\"calculated max_test_result per patient in {time.time() - t0}\")\n",
    "\n",
    "    if has_diet and make_diet_level_metrics:\n",
    "        with utils.Timer(\"Making patient-level diet questions count\", new_line=True):\n",
    "            d_pids_ = s.get(diet_dest['patient_id']).data[:]\n",
    "            d_pid_spans = s.get_spans(d_pids_)\n",
    "            d_distinct_pids = s.apply_spans_first(d_pid_spans, d_pids_)\n",
    "            d_pid_counts = s.apply_spans_count(d_pid_spans)\n",
    "            p_diet_counts = s.create_numeric(patients_dest, 'diet_counts', 'int32')\n",
    "            s.merge_left(left_on=s.get(patients_dest['id']).data[:], right_on=d_distinct_pids,\n",
    "                         right_fields=(d_pid_counts,), right_writers=(p_diet_counts,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_daily = # False or True to generate aggregated daily assessments\n",
    "input_filename = # File name for the imported dataset\n",
    "output_filename = # Filename to write the processed dataset to\n",
    "timestamp = str(datetime.now(timezone.utc)) # Override with a specific timestamp if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = set()\n",
    "if generate_daily is True:\n",
    "    flags.add('daily')\n",
    "\n",
    "with h5py.File(input_filename, 'r') as ds:\n",
    "    with h5py.File(output_filename, 'w') as ts:\n",
    "        postprocess(ds, ts, timestamp, flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
